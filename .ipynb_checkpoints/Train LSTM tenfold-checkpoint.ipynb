{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from shutil import copyfile\n",
    "from os import makedirs\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "os.chdir('/home/bruno.matosak/IGARSS2023/Pantanal/Landsat SR all/LSTM trainings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_series = np.load('./samples/filled_series.npy')/10000\n",
    "filled_reference = np.load('./samples/filled_reference.npy')\n",
    "\n",
    "raw_series = np.load('./samples/raw_series.npy')/10000\n",
    "raw_reference = np.load('./samples/raw_reference.npy')\n",
    "\n",
    "print(\"filled Series train shape   :\", filled_series.shape)\n",
    "print(\"filled Reference train shape:\", filled_reference.shape)\n",
    "\n",
    "print(\"raw    Series train shape   :\", raw_series.shape)\n",
    "print(\"raw    Reference train shape:\", raw_reference.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# shuffle functions\n",
    "\n",
    "# shuffle array\n",
    "def shuffle_array(array):\n",
    "    # shuffle things\n",
    "    s = np.asarray(array).copy()\n",
    "\n",
    "    ids = np.arange(0,len(s),1)\n",
    "    np.random.shuffle(ids)\n",
    "\n",
    "    ii = 0\n",
    "    for i in ids:\n",
    "        s[ii] = array[i]\n",
    "        ii+=1\n",
    "\n",
    "    return s\n",
    "\n",
    "# shuffle array according to positions given\n",
    "def shuffle_array_given_ids(array, ids):\n",
    "    shuffled = array.copy()\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        shuffled[i] = array[ids[i]]\n",
    "        \n",
    "    return shuffled\n",
    "\n",
    "# ==================================================\n",
    "# shuffling samples\n",
    "\n",
    "# array with samples ids to shuffle\n",
    "ids = np.arange(len(filled_reference))\n",
    "# shuffle ids\n",
    "ids = shuffle_array(ids)\n",
    "\n",
    "# shuffling samples according to shuffled ids\n",
    "filled_series    = shuffle_array_given_ids(filled_series, ids)\n",
    "filled_reference = shuffle_array_given_ids(filled_reference, ids)\n",
    "\n",
    "raw_series       = shuffle_array_given_ids(raw_series, ids)\n",
    "raw_reference    = shuffle_array_given_ids(raw_reference, ids)\n",
    "    \n",
    "# ==================================================\n",
    "# main iteration process - 10-fold\n",
    "i = 1\n",
    "kfold = StratifiedKFold(10, shuffle=True, random_state=1)\n",
    "for train_ids, test_ids in kfold.split(filled_series, filled_reference):\n",
    "    # ===============================================\n",
    "    # defining the function to train the model multiple times\n",
    "    def train_new_model(model_id, status, identifier, samples_train_series, samples_train_reference, samples_test_series, samples_test_reference):\n",
    "        # status: 'filled' or 'raw'\n",
    "        # identifier: string number zero padded for 3 digits, the number of the iteration\n",
    "        \n",
    "        # ===========================================\n",
    "        # defining model\n",
    "        input_dim = samples_train_series.shape[2]\n",
    "\n",
    "        units = 20\n",
    "        output_size = samples_train_reference.shape[1]\n",
    "\n",
    "        # Build the RNN model\n",
    "        def build_model(allow_cudnn_kernel=True, model_id=''):\n",
    "            # CuDNN is only available at the layer level, and not at the cell level.\n",
    "            # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "            # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "            if allow_cudnn_kernel:\n",
    "                # The LSTM layer with default options uses CuDNN.\n",
    "                lstm_layer1 = tf.keras.layers.LSTM(units, return_sequences=False, input_shape=(None, input_dim))\n",
    "                lstm_layer2 = tf.keras.layers.LSTM(units*2, return_sequences=True, input_shape=(None, input_dim))\n",
    "                lstm_layer3 = tf.keras.layers.LSTM(units*3, return_sequences=True, input_shape=(None, input_dim))\n",
    "                lstm_layer4 = tf.keras.layers.LSTM(units*4, return_sequences=True, input_shape=(None, input_dim))\n",
    "                lstm_layer5 = tf.keras.layers.LSTM(units*5, return_sequences=True, input_shape=(None, input_dim))\n",
    "            else:\n",
    "                # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "                lstm_layer1 = tf.keras.layers.RNN(\n",
    "                    tf.keras.layers.LSTMCell(units, return_sequences=False),\n",
    "                    input_shape=(None, input_dim))\n",
    "                lstm_layer2 = tf.keras.layers.RNN(\n",
    "                    tf.keras.layers.LSTMCell(units*2, return_Seuqences=True),\n",
    "                    input_shape=(None, input_dim))\n",
    "                lstm_layer3 = tf.keras.layers.RNN(\n",
    "                    tf.keras.layers.LSTMCell(units*3, return_Seuqences=True),\n",
    "                    input_shape=(None, input_dim))\n",
    "                lstm_layer4 = tf.keras.layers.RNN(\n",
    "                    tf.keras.layers.LSTMCell(units*4, return_Seuqences=True),\n",
    "                    input_shape=(None, input_dim))\n",
    "                lstm_layer5 = tf.keras.layers.RNN(\n",
    "                    tf.keras.layers.LSTMCell(units*5, return_Seuqences=True),\n",
    "                    input_shape=(None, input_dim))\n",
    "            \n",
    "            # the model\n",
    "            if model_id == 'model_1':\n",
    "                model = tf.keras.models.Sequential([lstm_layer1, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "            elif model_id == 'model_2':\n",
    "                model = tf.keras.models.Sequential([lstm_layer2, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer1, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "            elif model_id == 'model_3':\n",
    "                model = tf.keras.models.Sequential([lstm_layer3, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer2, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer1, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "            elif model_id == 'model_4':\n",
    "                model = tf.keras.models.Sequential([lstm_layer4, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer3, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer2, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer1, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "            elif model_id == 'model_5':\n",
    "                model = tf.keras.models.Sequential([lstm_layer5, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer4, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer3, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer2, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    lstm_layer1, \n",
    "                                                    tf.keras.layers.BatchNormalization(),\n",
    "                                                    tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "            \n",
    "            return model\n",
    "\n",
    "        # ================================================\n",
    "        # compiling model\n",
    "        model = build_model(allow_cudnn_kernel=True, model_id=model_id)\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                      optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # ================================================\n",
    "        # training the model\n",
    "        makedirs(f'./fit/{model_id}/{status}/' + identifier, exist_ok = True)\n",
    "        logdir = f'./fit/{model_id}/{status}/' + identifier\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        model.fit(samples_train_series,\n",
    "                  samples_train_reference,\n",
    "                  validation_data=(samples_test_series,\n",
    "                                   samples_test_reference),\n",
    "                  batch_size=64,\n",
    "                  epochs=200,\n",
    "                  verbose=0,\n",
    "                  callbacks=[tensorboard_callback])\n",
    "        \n",
    "        # ================================================\n",
    "        # save the model for later\n",
    "        model.save(f'./models/{model_id}/{status}/' + identifier + '.h5')\n",
    "        \n",
    "        # ================================================\n",
    "        # calculating val statistics\n",
    "        pred = tf.argmax(model.predict(samples_test_series, verbose=0), axis=1)\n",
    "        refe = tf.argmax(samples_test_reference, axis=1)\n",
    "        \n",
    "        cm = confusion_matrix(refe.numpy().ravel(), pred.numpy().ravel(), labels=[1,2,3,4,5])\n",
    "        \n",
    "        np.save(f'./models/{model_id}/{status}/' + identifier + '_cm.npy', cm)\n",
    "        \n",
    "        # =================================================\n",
    "        # clean things\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    # ======================================================\n",
    "    # print iteration\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'Iteration {i}')\n",
    "    print('-------------------------------------------------')\n",
    "    # ======================================================\n",
    "    # FILLED SAMPLES\n",
    "    # train and test datasets\n",
    "    print('Filled Samples')\n",
    "    samples_series_train = filled_series[train_ids]\n",
    "    samples_series_test  = filled_series[test_ids]\n",
    "    \n",
    "    samples_reference_train = tf.keras.utils.to_categorical(filled_reference[train_ids])\n",
    "    samples_reference_test  = tf.keras.utils.to_categorical(filled_reference[test_ids])\n",
    "    \n",
    "    # Create the model and stuff\n",
    "    for j in range(1,6,1):\n",
    "        t1 = time.time()\n",
    "        print(f'model_{j} ... ', end='')\n",
    "        train_new_model(f'model_{j}', 'filled', str(i).zfill(3), samples_series_train, samples_reference_train, samples_series_test, samples_reference_test)\n",
    "        tf.keras.backend.clear_session()\n",
    "        t2 = time.time()\n",
    "        print('%.3f minutes' % ((t2-t1)/60))\n",
    "    \n",
    "    print('-')\n",
    "    # ======================================================\n",
    "    # RAW SAMPLES\n",
    "    # train and test datasets\n",
    "    print('Raw Samples')\n",
    "    samples_series_train = raw_series[train_ids]\n",
    "    samples_series_test  = raw_series[test_ids]\n",
    "    \n",
    "    samples_reference_train = tf.keras.utils.to_categorical(raw_reference[train_ids])\n",
    "    samples_reference_test  = tf.keras.utils.to_categorical(raw_reference[test_ids])\n",
    "    \n",
    "    # Create the model and stuff\n",
    "    for j in range(1,6,1):\n",
    "        t1 = time.time()\n",
    "        print(f'model_{j} ... ', end='')\n",
    "        train_new_model(f'model_{j}', 'raw', str(i).zfill(3), samples_series_train, samples_reference_train, samples_series_test, samples_reference_test)\n",
    "        tf.keras.backend.clear_session()\n",
    "        t2 = time.time()\n",
    "        print('%.3f minutes' % ((t2-t1)/60))\n",
    "        \n",
    "    # =======================================================\n",
    "    # changing 1 for the next loop\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
